\documentclass{article}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
%\usepackage[french]{babel}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{listings}
\usepackage{cases}
\usepackage{enumerate}
\usepackage{stmaryrd}
\usepackage{amssymb}
\usepackage{xfrac}
\usepackage{amsfonts}
\usepackage{float}
\usepackage[margin=60pt]{geometry}


\author{Latrille Thibault\\
\small thibault.latrille@ens-lyon.fr\\[-0.8ex]}
\title{Relatedness and population dynamic.}  

\newcommand{\ud}{\mathrm{d}}

\begin{document}
\maketitle

Relatedness is a key component of inclusive fitness, it is a measure of how closely two individuals are related. The relatedness is highly dependent on the genealogy of the population and of recent coalescent, thus population dynamic is closely related to relatedness. We here derive analytic formula of relatedness under several models of population dynamic. 
\section{Distribution of population size during exponential growth.}

In this section, we seek to find the distribution of population size of an exponentially growing population of bacteria, for every time point.
 \paragraph{Notation} $ $\\
 $\bullet \quad t \in \mathbb{R}_+$ is the time variable along the growth\\
 $\bullet \quad N(t)$ is a random variable denoting the size of the population at time $t$\\
 $\bullet \quad P_n(t)$ is the probability mass function of $N(t)$, that is to say $P_n(t)=P(N(t)=n)$\\
 $\bullet \quad r$ is the initial population size\\
 $\bullet \quad \lambda$ is the infinitesimal birth rate\\
 

 The process described here is a Markov process. We assume that each bacteria has an independent constant birth rate $\lambda$ and that they never die. Biologically,  these assumption reflect the fact that we neglect competition, and also that the probability for a bacteria to divide is independent of its age. The Kolmogorov forward equations describing the population size distribution are:   
 \begin{subequations}
  \begin{numcases}{}
    \sum_{n \geq r} P_n(t)=1\\
    P_{r}(0)=1 \\
    P'_n(t)=(n-1)\lambda P_{n-1}(t)-n\lambda P_n(t)\text{ for } n \geq r. \label{eq:dif:exponential}
  \end{numcases}
 \end{subequations}
We then multiply the differential equation \eqref{eq:dif:exponential} by $(s^1,s^2,s^3,\hdots)$ and add. We obtain a single partial differential equation and the boundary conditions:
 \begin{subequations}
  \begin{numcases}{}
    		G(s,0)=s^{r} \\
    		G(1,t)=1 \\
    		G(0,t)=0 \\
    		\dfrac{\partial G_{N(t)}(s)}{\partial t} = \lambda s(s-1) \dfrac{\partial G_{N(t)}(s)}{\partial s} \text{ for } s \in [0,1], \label{eq:dif:exponential:partial}
 \end{numcases}
 \end{subequations}
 where $\displaystyle G_{N(t)}(s)=\sum_{i=1}^{\infty} P_i(t)s^i=\mathbb{E}[ s^{N(t)}] $ is the probability generating function of $N(t)$. \\
The probability generating function (pgf) satisfying this equation (\textit{reference needed}) is:

\begin{equation}
G_{N(t)}(s)=\left( \dfrac{s e^{-\lambda t}}{1-s+s e^{-\lambda t}} \right)^r=\left( \dfrac{sp(t)}{1-s[1-p(t)]} \right)^r \text{ where }p(t)=e^{-\lambda t}.
\end{equation}

Thus the distribution of $N(t)$ is of the negative binomial form (\textit{reference needed}), with support on $\llbracket r ,\infty \llbracket$, that is to say: 
\begin{equation}
P_n(t)=P(N(t)=n)=\binom{n-1}{r-1} p(t)^r [1-p(t)]^{n-r} \text{ for } n \geq r.
\end{equation}

 
 \section{Identity by descendant during exponential growth.}
 In this section, we deal with several exponentially growing families. We assume that families are independent of one another and that each family has the same growth rate but there initial size can differ. We derive the probability of identity (PI), \textit{i.e.} the probability that two randomly chosen are picked from the same family. We used two different methods to derive the PI, the first method rely on the explicit formulation of the distribution, the second one relies solely on the pgf.
 \\
  \paragraph{Notation} $ $\\
 $\bullet \quad d>1$ is the number of families\\
 $\bullet \quad r_i $ for $1 \leq i \leq d$ is the initial size of the $i$\textsuperscript{th} family\\
 $\displaystyle \bullet \quad r_+=\sum_{i=0}^d r_i$ is the initial size of the population \\
 $\bullet \quad N_i(t) $ is the random variable denoting the size of the $i$\textsuperscript{th} family at time $t$ \\
 $\displaystyle \bullet \quad N_+(t)=\sum_{i=0}^d N_i(t)$ is the random variable denoting the size of the population at time $t$ \\
 $\bullet \quad p(t)=e^{-\lambda t} $ as in the previous section\\
 
 \subsection{First method, using distributions.}
  To evaluate the PI, we first need to compute the distribution of size of one single family, conditional on the size of the total population. This conditional distribution is then used to evaluate the PI.
 Let us denote $X_i(t)=N_i(t)-r_i$, the number of births. $X_i$ has support on $\mathbb{N}$ and follows a negative binomial distributions with parameters $r_i$ and $p(t)$:

\begin{equation}
X_i \sim \textrm{NB}(r_i,p(t)) \iff P(X_i(t)=x)=\binom{x+r_i-1}{x} p(t)^{r_i} [1-p(t)]^{x} \text{ for } x \geq 0.
\end{equation}

This second form of the negative binomial is used for convenience since calculus are more tractable and direct in this way.\\


Let $X_i(t) \sim \textrm{NB}(r_i,p(t))$ for $1 \leq i \leq d$, and denote $X_+(t)=\sum_{i=0}^d X_i(t)$. The sum of independent negative binomials is a negative binomial, since the product of the pgf lead to the same formula:

\begin{equation}
 X_+(t)  \sim \textrm{NB} \left( r_+, p(t) \right). \label{sumNB}
\end{equation}


Let $(x,x_+) \in \mathbb{N}_+^2$ such that $0 \leq x \leq x_+$. And denote $ \displaystyle r_{-i}=\sum_{j \neq i} r_j=r_+-r_i$, then

\begin{align}
P( X_i(t)=x \vert X_+(t)=x_+ ) &=\dfrac{P\left( X_i(t)=x \cap \sum_{j \neq i} X_i(t)=x_+-x \right)}{P\left(X_+(t)=x_+\right)} \text{ by Bayes formula}\\
 &=\dfrac{P\left(X_i(t)=x\right) P\left(\sum_{j \neq i} X_j(t)=x_+-x\right)}{P\left(X_+(t)=x_+\right)} \text{ by independence}\\
 &=\dfrac{\displaystyle \binom{x+r_i-1}{x} p(t)^{r_i} [1-p(t)]^{x} \binom{x_+-x+r_{-i}-1}{x_+-x} p(t)^{r_{-i}} [1-p(t)]^{x_+-x} }{\displaystyle \binom{x_++r_+ -1}{x_+} p(t)^{r_+ } [1-p(t)]^{x_+}} \text{ by \eqref{sumNB}} \\
 &=\dfrac{\displaystyle \binom{x+r_i-1}{x} \binom{x_+-x+r_{-i}-1}{x_+-x}}{\displaystyle \binom{x_+ +r_+ -1}{x_+}}.
\end{align}
 
 Thus the distribution of $X_i(t)$ conditional on $ X_+(t)=x_+$ is of the negative hypergeometric form (\textit{reference needed}) and is independent of $p(t)$.
 
 Computation of the first and second moments is straightforward (\textit{reference needed}): 
 
\begin{align}
\mathbb{E} [ X_i(t) \vert X_+(t)=x_+ ] &=\dfrac{r_i x_+}{r_+ } \\
\mathbb{E} [ X_i(t)^2 \vert X_+(t)=x_+ ] &=\dfrac{r_i x_+ (r_{-i} +x_+ (r_i+1))}{r_+ (1+r_+ )}.
\end{align}

Leading to expectation for $X_i(t)(X_i(t)-1)$ conditional on $X_+(t)$:
\begin{equation}
 \mathbb{E} [ X_i(t)(X_i(t)-1) \vert X_+(t)=x_+ ] =\dfrac{r_i(r_i+1) x_+ ( x_+ -1 ) }{r_+ (r_+ +1 )}. \label{condexpX}
\end{equation}

Using \eqref{condexpX} and the relation $N_i(t)=X_i(t)+r_i$ we derive the expectation for $N_i(t)(N_i(t)-1)$ conditional on $N_+(t)$:
\begin{align}
 \mathbb{E} [ N_i(t)(N_i(t)-1) \vert N_+(t)=n_+ ] &= \mathbb{E} [ ( X_i(t)+r_i)(X_i(t)+r_i -1) \vert X_+(t)+ r_+ = n_+ ] \\
 &= \mathbb{E} [r_i(r_i-1) + 2r_i X_i(t) + X_i(t)(X_i(t)-1) \vert X_+(t)=n_+ - r_+ ]\\
 &= r_i(r_i-1) + 2 r_i \mathbb{E} [ X_i(t) \vert X_+(t)=n_+ - r_+ ]\\
 & \qquad + \mathbb{E} [X_i(t)(X_i(t)-1) \vert X_+(t)=n_+ - r_+ ]\\
  &= r_i(r_i-1) + 2 r_i \dfrac{r_i (n_+ - r_+)}{r_+ } + \dfrac{r_i(r_i+1) (n_+ - r_+) ( n_+ - r_+ -1 ) }{r_+ (r_+ +1 )}\\
 &=\dfrac{r_i(r_i+1) n_+ ( n_+ -1 ) }{r_+ (r_+ +1)} -\dfrac{2 r_{i} (r_+ - r_i) n_+ }{r_+ (r_+ +1)}. \label{condexpN}
\end{align}
 
Leading to the PI of family $i$ conditional on $N_+(t)$, \textit{i.e.} the probability that two bacteria are from family $i$ given the size of the population. 
\begin{align}
  \mathbb{E}\left[ \left. \dfrac{N_i(t)(N_i(t)-1)}{N_+(t)( N_+(t)-1 ) } \right\vert N_+(t)=n_+ \right] &= 
 \dfrac{\mathbb{E}[ N_i(t)(N_i(t)-1) \vert N_+(t)=n_+] }{n_+ (n_+ -1 ) }  \\
 &=\dfrac{r_i(r_i+1)}{r_+ (r_+ +1)} \dfrac{n_+ (n_+ -1 ) }{ n_+ (n_+ -1 ) }- \dfrac{2 r_i (r_+ -r_{i})}{r_+ (r_+ +1)} \dfrac{n_+}{ n_+ (n_+ -1 ) } \text{ by \eqref{condexpN}}\\
 &=\dfrac{r_i(r_i+1)}{r_+ (r_+ +1)}- \dfrac{2 r_i (r_+ -r_{i})}{r_+ (r_+ +1)} \dfrac{1}{ n_+ -1  }. \label{RelatednesscondexpN}
\end{align}

By taking expectation of the PI of family $i$ conditional on $N_+(t)$, over the distribution of $N_+(t)$, we get the PI of family $i$:

\begin{align}
\mathbb{E}\left[ \dfrac{N_i(t)(N_i(t)-1)}{N_+(t) ( N_+(t)-1 )} \right] &= 
 \mathbb{E}\left[ \mathbb{E}\left[ \left. \dfrac{N_i(t)(N_i(t)-1)}{N_+(t)( N_+(t)-1 ) } \right\vert N_+(t) \right] \right]\\
 &=\mathbb{E}\left[\dfrac{r_i(r_i+1)}{r_+ (r_+ +1)}- \dfrac{2 r_i (r_+ -r_{i})}{r_+ (r_+ +1)} \dfrac{1}{N_+(t)-1) } \right] \text{ by \eqref{condexpN}}\\
 &=\dfrac{r_i(r_i+1)}{r_+ (r_+ +1 )}-\dfrac{2 r_i (r_+ -r_{i})}{r_+ (r_+ +1 )}\mathbb{E}\left[\dfrac{1}{N_+(t)-1} \right].
\end{align}

Since $N_+(t) \sim \textrm{NB} (r_+, p(t))$ we can evaluate the expectation $\mathbb{E}\left[\dfrac{1}{N_+(t)-1} \right]$:

\begin{align}
\mathbb{E}\left[\dfrac{1}{N_+(t)-1} \right] &= \sum_{x=r_+}^{\infty } \dfrac{1}{x-1} \binom{x-1}{r_+-1} p(t)^{r_+} [1-p(t)]^{x-r_+} \\
 &=\sum_{y=r_+-1}^{\infty} \dfrac{1}{y} \binom{y}{r_+-1} p(t)^{r_+} [1-p(t)]^{y+1-r_+} \text{ with }y=x-1\\
 &=\dfrac{p(t)}{r_+-1}\sum_{y=r_+-1}^{\infty}\binom{y-1}{(r_+-1)-1} p(t)^{r_+-1} [1-p(t)]^{y-(r_+-1)} \\
 &=\dfrac{p(t)}{r_+-1}.
\end{align}

Thus the probability that two bacteria are from family $i$ is:
\begin{align}
\mathbb{E}\left[ \dfrac{N_i(t)(N_i(t)-1)}{N_+(t) ( N_+(t)-1 )} \right] &= \mathbb{E}\left[\dfrac{1}{N_+(t)-1} \right]\\
 &=\dfrac{r_i(r_i+1)}{r_+ (r_+ +1 )}-\dfrac{2 r_i (r_+ -r_{i})}{r_+ (r_+ +1 )}\dfrac{p(t)}{r_+-1}\\
 &=\dfrac{r_i(r_i+1)}{r_+ (r_+ +1 )}-\dfrac{2 r_i (r_+ -r_{i})p(t)}{r_+ (r_+^2 -1 )}. \label{PI:family}
\end{align}


By summing \eqref{PI:family} over all families, we evaluate the overall probability that two bacteria are from the same family:
\begin{align}
\mathbb{E}\left[ \displaystyle \sum_{i=0}^d \dfrac{N_i(t)(N_i(t)-1)}{N_+(t)(N_+(t)-1)} \right] &= \displaystyle \sum_{i=0}^d \mathbb{E}\left[  \dfrac{N_i(t)(N_i(t)-1)}{N_+(t)( N_+(t)-1 ) } \right]\\
&= \displaystyle \sum_{i=0}^d \left[ \dfrac{r_i(r_i+1)}{r_+ (r_+ +1 )}-\dfrac{2 r_i (r_+ -r_{i})p(t)}{r_+ (r_+^2 -1 )} \right] \\
&=    \dfrac{ r_+ + \sum_{i=0}^d r_i^2}{r_+ (r_+ +1)}  -2 e^{-\lambda t} \dfrac{ r_+^2-\sum_{i=0}^d r_i^2}{r_+ (r_+^2 -1) }. \label{PI}
\end{align}

If we assume $r_i=r$ for $0 \leq i \leq d$, the previous formula reduces to:
\begin{align}
\mathbb{E}\left[ \displaystyle \sum_{i=0}^d \dfrac{N_i(t)(N_i(t)-1)}{N_+(t)\left(N_+(t)-1 \right)} \right] &=
 \dfrac{ rd + r^2 d}{rd (rd +1)}  -2 e^{-\lambda t} \dfrac{ (rd)^2-r^2d}{rd [(rd)^2 -1] }\\
 &= \dfrac{r+1}{rd+1}  -2e^{-\lambda t} \dfrac{r(d-1)}{(rd)^2 -1 }.
\end{align}

Which equal $0$ at $t=0$ if $r=1$.

 \subsection{Second method, using probability generating functions.}
 We seek to derive the probability of identity directly as function of the joint pgf of $N_i(t)$ and $N_+(t)$.
 
 Let $G_{N_i(t) ,N_+(t)}(s_i,s_+)$ be the pgf of the joint distribution of $N_i(t)$ and $N_+(t)$. We have the following relation:
 
 \begin{align}
 \displaystyle \int_0^1 \int_0^y \dfrac{\partial^2 }{\partial s_i^2} & \left( \dfrac{G_{N_i(t) ,N_+(t)}(s_i,s_+)}{s_+^2} \right)_{s_i =1} \ud s_+ \ud y \\
 &= \int_0^1 \int_0^y \dfrac{\partial^2 }{\partial s_i^2} \left( \sum_{n_i,n_+ \geq 1} P(N_i(t)=n_i \cap N_+(t)=n_+) s_+^{n_+ -2} s_1^{n_1} \right)_{s_i =1} \ud s_+ \ud y \\ 
 &= \sum_{n_i,n_+ \geq 1} P(N_i(t)=n_i \cap N_+(t)=n_+) \left.  \dfrac{\partial^2 s_i^{n_i}}{\partial s_i^2} \right\vert_{s_i=1} \int_0^1 \int_0^y s_+^{n_+-2} \ud s_+ \ud y\\
 &= \sum_{n_i  ,n_+ \geq 1} P(N_i(t)=n_i \cap N_+(t)=n_+) \dfrac{n_i(n_i-1)}{n_+(n_+-1)}\\
 &= \mathbb{E}\left[ \dfrac{N_i(t)(N_i(t)-1)}{N_+(t) ( N_+(t)-1 )} \right].
 \end{align}
 
 Moreover $G_{N_i(t) ,N_+(t)}(s_i,s_+)$ can be reduced to the product of two pgf: 
  \begin{align}
G_{N_i(t) ,N_+(t)}(s_i,s_+,t) &= \mathbb{E} [ s_i^{N_i(t)} s_+^{N_+(t)}] \\
		&= \mathbb{E} [ s_i^{N_i(t)} s_+^{N_i(t)+N_{-i}(t)}]\\
		&= \mathbb{E} [ (s_i s_+)^{N_i(t)} s_+^{N_{-i}(t)}] \\
		&= \mathbb{E} [ (s_i s_+)^{N_i(t)} ]\mathbb{E} [ s_+^{N_{-i}(t)}] \\
		&= G_{N_i(t)}(s_i s_+) G_{N_{-i}(t)}(s_+).
 \end{align}
 
 Hence, we have 
   \begin{align}
\displaystyle \int_0^1 \int_0^y \dfrac{\partial^2 }{\partial s_i^2} \left( \dfrac{G_{N_i(t) ,N_+(t)}(s_i,s_+)}{s_+^2} \right)_{s_i =1} \ud s_+ \ud y
 &= \int_0^1 \int_0^y \dfrac{\partial^2 }{\partial s_i^2} \left( \dfrac{ G_{N_i(t)}(s_i s_+) G_{N_{-i}(t)}(s_+)}{s_+^2} \right)_{s_i =1} \ud s_+ \ud y \\
  &= \int_0^1 \int_0^y \dfrac{G_{N_{-i}(t)}(s_+)}{s_+^2} \left. \dfrac{\partial^2  G_{N_i(t)}(s_i s_+)  }{\partial s_i^2} \right\vert_{s_i =1} \ud s_+ \ud y \\
    &= \int_0^1 \int_0^y G_{N_{-i}(t)}(s_+) \dfrac{\partial^2  G_{N_i(t)}(s_+)  }{\partial s_+^2} \ud s_+ \ud y.
 \end{align}
 
 Thus the PI is a function solely of $G_{N_{i}(t)}$ and $G_{N_{-i}(t)}$:
 \begin{equation}
 \displaystyle \mathbb{E}\left[ \dfrac{N_i(t)(N_i(t)-1)}{N_+(t) ( N_+(t)-1 )} \right]= \int_0^1 \int_0^y G_{N_{-i}(t)}(s) \dfrac{\partial^2 G_{N_i(t)}(s)}{\partial s^2} \ud s \ud y.
 \end{equation}

This can be evaluated with Mathematica and it gives the same result as previously.


\section{Exponential growth of bacteria, birth-death process.}

In this section we extend the pure birth process to a birth-death process, adding linear a death process.
 \paragraph{Notation} $ $\\
 $\bullet \quad t \in \mathbb{R}_+$, the time variable along the growth\\
 $\bullet \quad P_n(t)$, the probability that the population at time $t$ is of size $n$.\\
 $\bullet \quad N(t)$, the random variable with law $P(N(t)=n)=P_n(t)$\\
 $\bullet \quad r$ the initial population size\\
 $\bullet \quad \lambda$ the infinitesimal birth rate\\
 $\bullet \quad \mu$ the infinitesimal death rate\\
 
 
 The process is such that each bacteria has an independent birth rate $\lambda$ and a death rate $\mu$. Thus the forward equation is:   
 \begin{subequations}
  \begin{numcases}{}
    \sum_{i \geq 1} P_n(t)=1\\
    P_{r}(0)=1 \\
    P'_i(t)=\lambda (i-1) P_{i-1}(t)+\mu (i+1)P_{i+1}(t)-i(\lambda+\mu)P_i(t)\text{ for } i\geq 1 \label{eq:dif:BD}
  \end{numcases}
 \end{subequations}
Multiply the differential equation \eqref{eq:dif:BD} by $(s^1,s^2,s^3,\hdots)$ and add. We obtain a single partial differential equation:
 \begin{subequations}
  \begin{numcases}{}
    		G(s,0)=s^{r} \\
    		G(1,t)=1 \\
    		G(0,t)=0 \\
    		\dfrac{\partial G(s,t)}{\partial t} = (\lambda s -\mu)(s-1) \dfrac{\partial G(s,t)}{\partial s} \text{ for } s \in [0,1] \label{eq:dif:BD:partial}
 \end{numcases}
 \end{subequations}
 with $\displaystyle G(s,t)=\sum_{i=1}^{\infty} P_i(t)s^i=\mathbb{E}[ s^{N(t)}] $ the probability generating function of $N(t)$. \\
The probability generating function satisfying this equation is :

\begin{equation}
\displaystyle  G(s,t)=  \left( \dfrac{\mu (1-s)-(\mu- \lambda s) \exp^{-(\lambda - \mu )t}}{\lambda (1-s)-(\mu -\lambda s) \exp^{-(\lambda -\mu )t}} \right)^{r} \text{ for } s \in [0,1].
\end{equation}
 
\section{Logistic growth of bacteria}

In this section we extend the previous processes to a birth-death process, adding non linear a death process due to competition.

 \paragraph{Notation} $ $\\
 $\bullet \quad t \in \mathbb{R}_+$, the time variable along the growth\\
 $\bullet \quad P_n(t)$, the probability that the population at time $t$ is of size $n$.\\
 $\bullet \quad N(t)$, the random variable with law $P(N(t)=n)=P_n(t)$\\
 $\bullet \quad r$ the initial population size\\
 $\bullet \quad \lambda$ the infinitesimal birth rate\\
 $\bullet \quad c$ the infinitesimal competition rate\\ 
 
 The process is such that each bacteria has an independent birth rate $\lambda$, and the death is only due to competition such that each bacteria dies out a rate $n\lambda$, where $n$ is the number of other bacteria. Thus the forward equation is:   
 \begin{subequations}
  \begin{numcases}{}
    \sum_{i \geq 1} P_n(t)=1\\
    P_{r}(0)=1 \\
    P'_i(t)=(i-1)\lambda P_{i-1}(t)+ci(i+1)P_{i+1}(t)-i(\lambda+c(i-1))P_i(t)\text{ for } i\geq 1 \label{eq:dif}
  \end{numcases}
 \end{subequations}
Multiply the differential equation \eqref{eq:dif} by $(s^1,s^2,s^3,\hdots)$ and add. We obtain a single partial differential equation:
 \begin{subequations}
  \begin{numcases}{}
    		G(s,0)=s^{r} \\
    		G(1,t)=1 \\
    		G(0,t)=0 \\
    		\dfrac{\partial G(s,t)}{\partial t} = \lambda s(s-1) \dfrac{\partial G(s,t)}{\partial s} + c s(1-s) \dfrac{\partial^2 G(s,t)}{\partial s^2} \text{ for } s \in [0,1] \label{eq:dif:partial}
 \end{numcases}
 \end{subequations}
 with $\displaystyle G(s,t)=\sum_{i=1}^{\infty} P_i(t)s^i=\mathbb{E}[ s^{N(t)}] $ the probability generating function of $N(t)$. \\
At equilibrium, with $\rho = \sfrac{\lambda}{c} $, the probability generating function satisfying this equation is :
\begin{equation}
\displaystyle  G(s,\infty)= \sum_{i\geq 1} \dfrac{e^{-\rho}}{1-e^{-\rho}} \dfrac{ \rho^i}{i!} s^i = \dfrac{e^{-\rho}}{1-e^{-\rho}} \left( e^{s \rho} -1 \right) \text{ for } s \in [0,1]
\end{equation}

  And the associated limiting distribution is that of a Poisson variable, conditioned on being positive: 
 \begin{equation}
 \displaystyle P_i(\infty)=\dfrac{e^{-\rho}}{1-e^{-\rho}} \dfrac{ \rho^i}{i!} \text{ for } i\geq 1
 \end{equation}
 
 Denote $G(s,t)=e^{s \sfrac{\lambda}{2c}}K(s,t)$ and the \eqref{eq:dif:partial} become :
 \begin{subequations}
  \begin{numcases}{}
    		K(0,t)=0 \\
    		\dfrac{\partial K(s,t)}{\partial t} = \dfrac{\lambda^2}{2c} s(s-1) K(s,t) + c s(1-s) \dfrac{\partial^2 K(s,t)}{\partial s^2} \text{ for } s \in [0,1] 
 \end{numcases}
 \end{subequations}
 
 
 Multiply the differential equation \eqref{eq:dif} by $(e^{-\theta},e^{-2\theta},e^{-3\theta},\hdots)$ and add. We obtain a single partial differential equation:
  \begin{subequations}
  \begin{numcases}{}
    		H(0,t)=1 \\
    		H(\theta ,0)=e^{-\theta r } \\
    		\dfrac{\partial H(\theta,t)}{\partial t} = \lambda (1-e^{-\theta}) \dfrac{\partial H(\theta,t)}{\partial \theta} + c (e^{\theta}-1) \left( \dfrac{\partial H(\theta,t)}{\partial \theta}+\dfrac{\partial^2 H(\theta,t)}{\partial \theta ^2} \right) \text{ for } \theta \in \mathbb{R_+}
 \end{numcases}
 \end{subequations}
 with $\displaystyle H(s,t)=\sum_{i=1}^{\infty} P_i(t)e^{-i \theta }=\mathbb{E}[ e^{-\theta N(t)}]$ the moment generating function of $N(t)$. \\

\section{Biological model and Relatedness.}
 \paragraph{Notation} $ $\\
 $\bullet \quad t \in [0, t_{max}]$, the time variable along the growth\\
 $\bullet \quad Q_0^J$ the probability of identity of two bacteria in the same nematode during the free state\\
 $\bullet \quad Q_1^J$ the probability of identity of two bacteria in a different nematode during the free state\\
 $\bullet \quad Q_0(t)$ the probability of identity of two bacteria in the same insect during growth\\
 $\bullet \quad Q_1(t)$ the probability of identity of two bacteria in a different insect during growth\\
 $\bullet \quad n_{I}$ the number of insects\\
 $\bullet \quad V$ the number of nematodes infecting the insect\\
 
  \begin{subequations}
  \begin{numcases}{}
      		Q_0^{J} = 1 \\
    		Q_1^{J} = \dfrac{Q_0(t_{max})}{n_{I}} +\dfrac{n_{I}-1}{n_{I}} Q_1(t_{max})\\
    		Q_1'(t) = Q_1^J\\
    		Q_0'(t) = {\mathbb E}_{N_1(t), \hdots, N_V(t) } \left[ \displaystyle  \sum_{i=1}^V \dfrac{ N_i(t)(N_i(t)-1)}{ N_+(t)( N_+(t) -1 )} \right] + Q_1^J {\mathbb E}_{N_1(t), \hdots, N_V(t) } \left[ \displaystyle  \sum_{i=1}^V \sum_{j=1}^{i-1} \dfrac{  2 N_i(t) N_j(t)}{ N_+ (t)( N_+ (t)-1 )} \right].
  \end{numcases}
 \end{subequations}
 
 Hence, in a more compact way: 
 
  \begin{subequations}
  \begin{numcases}{}
      		Q_0'(t_{max}) = \psi + \left( \dfrac{Q_0(t_{max})}{n_{I}}+\dfrac{n_{I}-1}{n_{I}} Q_1(t_{max}) \right) (1 -\psi) \\
    		    		Q_1'(t_{max}) = \dfrac{Q_0(t_{max})}{n_{I}}+\dfrac{n_{I}-1}{n_{I}} Q_1(t_{max}),
  \end{numcases}
 \end{subequations}
 
 \begin{equation}
 \text{where }\psi \equiv \psi(t_{max})={\mathbb E}_{N_1(t_{max}), \hdots, N_V(t_{max}) } \left[ \displaystyle  \sum_{i=1}^V \dfrac{ N_i(t_{max})(N_i(t_{max})-1)}{ N_+(t_{max})( N_+(t_{max}) -1 )} \right].. \label{psi}
 \end{equation}
  
\subsection{Derivation of relatedness for infinite number of insects.}
Under the assumption of an infinite number of demes ($n_{I} \rightarrow \infty$), both $Q_1^J$ and $Q_1(t)$ equal $0$. Thus the recursion equation at equilibrium for $Q_0(t_{max})$ is solve unambiguously and give the relatedness $R$:

\begin{equation}
R \simeq Q_0(t_{max}) \simeq \psi. \label{R=psi}
\end{equation}


\subsection{Derivation of relatedness for low mutation rate.}
Taking mutation rate $u$ into account, the recursion equations become: 
  \begin{subequations}
  \begin{numcases}{}
      		Q_0'(t_{max}) = (1-u)^2 \left[ \psi + \left( \dfrac{Q_0(t_{max})}{n_{I}}+\dfrac{n_{i}-1}{n_{I}} Q_1(t_{max}) \right) (1 -\psi) \right] \\
    		    		Q_1'(t_{max}) = (1-u)^2 \left[ \dfrac{Q_0(t_{max})}{n_{I}}+\dfrac{n_{i}-1}{n_{I}} Q_1(t_{max}) \right].
  \end{numcases}
 \end{subequations}
 
 At equilibrium, $Q_0'(t_{max})=Q_0(t_{max})$ and $Q_1'(t_{max})=Q_1(t_{max})$ and the recursion equations are:
 \begin{subequations}
  \begin{numcases}{}
      		Q_0(t_{max}) = (1-u)^2 \left[ \psi + \left( \dfrac{Q_0(t_{max})}{n_{I}}+\dfrac{n_{i}-1}{n_{I}} Q_1(t_{max}) \right) (1 -\psi) \right] \\
    		    		Q_1(t_{max}) = (1-u)^2 \left[ \dfrac{Q_0(t_{max})}{n_{I}}+\dfrac{n_{i}-1}{n_{I}} Q_1(t_{max}) \right].
  \end{numcases}
 \end{subequations}
 
 Leading to the unique solution:
 
 \begin{align}
 Q_0(t_{max}) &= \dfrac{ (1-u)^2 [u (2 - u)(n_{I}-1) +1 ]\psi }{ u (2-u )(n_{I} - \psi )+\psi }\\
 Q_1(t_{max}) &= \dfrac{(1- u )^4 \psi}{u (2-u) (n_{I} - \psi ) +\psi}.
 \end{align}

 And the relatedness is: 
 
 \begin{equation}
 R(u)=\dfrac{Q_0(t_{max})-Q_1(t_{max})}{1-Q_1(t_{max})}=\dfrac{(1-u)^2 n_{I} \psi}{n_{I} +(1-u)^2 \psi}.
 \end{equation}
 
And thus by taking the limit for low mutation rate ($u \rightarrow 0$), the relatedness becomes:
 \begin{equation}
 R \simeq \lim_{u \to 0} R(u)=\dfrac{n_{I} \psi}{n_{I} + \psi}=\dfrac{\psi}{1+ \dfrac{\psi}{n_{I}}}. \label{R=psi(nI)}
 \end{equation}
 
 \section{Deterministic arrival time of nematodes.}
 
 \paragraph{Notation} $ $\\
 $\bullet \quad V$ the number of nematodes infecting the insect\\
 $\bullet \quad \tau$ the rate of arrival of nematodes in the insect\\
 $\bullet \quad \lambda$ the birth rate of bacteria in the insect\\
 $\bullet \quad r_i$ $( 1 \leq i \leq V )$ the number of bacteria from the $i$th nematode at the time of infection by the last nematode\\
 $\bullet \quad r$ the number of bacteria carried by a nematode \\
 $\bullet \quad q=e^{\sfrac{ \lambda}{\tau}}$
 

 Assume $r_i \gg 1$, $ 1 \leq i \leq V $, the function $\psi$ defined earlier simplify to 
 
 \begin{align}
 \psi &={\mathbb E}_{N_1(t_{max}), \hdots, N_V(t_{max}) } \left[ \displaystyle  \sum_{i=1}^V \dfrac{ N_i(t_{max})(N_i(t_{max})-1)}{ N_+(t_{max})( N_+(t_{max}) -1 )} \right] \text{ by } \ref{psi} \\
 &= \dfrac{ r_+ + \sum_{i=0}^V r_i^2}{\sum_{i=0}^V r_i \left(\sum_{i=0}^V r_i +1\right) }  -2 e^{-\lambda t_{max}} \dfrac{ \left(\sum_{i=0}^V r_i\right)^2-\sum_{i=0}^V r_i^2}{\sum_{i=0}^V r_i \left( \left(\sum_{i=0}^V r_i\right)^2 -1\right) } \text{ by }\ref{PI} \\
 & \simeq \dfrac{ \sum_{i=0}^V r_i^2}{\left(\sum_{i=0}^V r_i\right)^2}, \label{simplify:relatedness}
 \end{align}
 which is independent of both $\lambda$ and $t_{max}$.
 
 
 Let us assume that the arrival time of nematodes are deterministic, assume also that the growth of bacteria prior to the infection by the last nematode is deterministic. The initial number $r_i$ of bacteria from $i$th last arrived nematode are of the form $r_i=r e^{\lambda \sfrac{ (i-1) }{\tau}}=r (e^{\sfrac{ \lambda}{\tau}})^{i-1}=r q^{i-1}$, for $ 1 \leq i \leq V$.
 $\psi$ is then approximated by: 
 
 \begin{align}
  \psi &\simeq \dfrac{ \sum_{i=0}^V r^2 (q^2)^{i-1}}{\left(\sum_{i=0}^V r q^{i-1}\right)^2} = \dfrac{ \sum_{i=0}^V (q^2)^{i-1}}{\left(\sum_{i=0}^V q^{i-1}\right)^2}= \dfrac{q^{2V} -1 }{q^{2} -1 } \dfrac{(q-1)^2}{(q^V -1)^2} \\
  &= \dfrac{(q-1)(q^V +1)}{(q+1)(q^V -1)} = \dfrac{(e^{\sfrac{ \lambda}{\tau}}-1)((e^{\sfrac{ \lambda}{\tau}})^V +1)}{(e^{\sfrac{ \lambda}{\tau}}+1)((e^{\sfrac{ \lambda}{\tau}})^V -1)}.
 \end{align}
 Under the model of infinite number of insects, the relatedness is 
 
 \begin{equation}
 R \simeq \psi \simeq  \dfrac{(q-1)(q^V +1)}{(q+1)(q^V -1)} \text{ by }\ref{R=psi}.
 \end{equation}
 It is worth noticing that the relatedness does not depend on the number of bacteria initially brought by the nematode ($r$), nor on the the total population size when the bacteria stop growing exponentially. 
 This formula is valid only if the population of bacteria is growing exponentially at the time the last nematode infected the insect.
 
 $\bullet$ If the birth rate of bacteria is far superior than the infection rate we have:
 \begin{equation}
 \tau \ll \lambda \Rightarrow q \gg 1 \Rightarrow R \simeq 1,
 \end{equation}
 The relatedness is close to one, all bacteria are from the same nematode.
 
 
 $\bullet$ If the birth rate of bacteria is far inferior to the infection rate we have:
 \begin{equation}
 \tau \gg \lambda \Rightarrow q \simeq 1 + \frac{\lambda }{\tau } \Rightarrow R \simeq 
  \dfrac{\dfrac{\lambda}{\tau}\left( \dfrac{V\lambda}{\tau} +2\right)}{\left( \dfrac{\lambda}{\tau} +2\right)\dfrac{V\lambda}{\tau}} \simeq \dfrac{1}{V}.
 \end{equation}
  The relatedness is close to $V^{-1}$, as if all nematodes were infected simultaneously.
  
  This raises the question : The cooperation evolves only for a certain quantity of nematodes infecting the insect and for a certain ratio of arrival rate/ growth rate.

Under the model of finite number of insects, the relatedness is then approximated by: 
 
 \begin{align}
  R & \simeq \dfrac{\psi}{1+ \dfrac{\psi}{n_{I}}} \simeq \dfrac{(q-1)(q^V +1)}{(q+1)(q^V -1)} \left( 1+ \dfrac{(q-1)(q^V +1)}{n_I (q+1)(q^V -1)} \right)^{-1} \text{ by }\ref{R=psi(nI)}\\
    &= \dfrac{(q-1)(q^V+1)}{ (q+1)(q^V -1)+ \dfrac{(q-1)(q^V +1)}{n_I}}.
 \end{align}
 
 
 $\bullet$ If the birth rate of bacteria is far superior than the infection rate we have:
 \begin{equation}
 \tau \ll \lambda \Rightarrow q \gg 1 \Rightarrow R \simeq \dfrac{1}{1+n_I},
 \end{equation}
 
 $\bullet$ If the birth rate of bacteria is far inferior to the infection rate we have:
 \begin{equation}
 \tau \gg \lambda \Rightarrow q \simeq 1 + \frac{\lambda }{\tau } \Rightarrow R \simeq \dfrac{n_I}{n_I V +1}.
 \end{equation}

 \section{Fitness function and derivation of equilibrium.}
 
 In this section we make use of the previous results for the derivation of evolutionary stable strategies.
 \subsection{Bacteria feeding the nematode}
 In this case we are interested in a phenotype of bacteria feeding the nematodes after they finished growing exponentially. We assume the bacteria can choose to sacrifice itself to feed a nematode and thus increase the fitness of this focal nematode.
 
  \paragraph{Notation} $ $\\
 $\bullet \quad n_I$ the number of insects \\
 $\bullet \quad R$ the relatedness as previously \\
 $\bullet \quad z$ the phenotype of bacteria measuring the probability the individual(s) will sacrifice it(them)self to feed a nematode\\
 $\bullet \quad z_\bullet $ the phenotype $z$ for the focal individual\\
 $\bullet \quad z_j$ the phenotype $z$ for the individuals in the $j$th deme (the insect)\\
 $\bullet \quad \mathbf{z}=(z_1,\cdots,z_{n_I})$ the vector of $z_j$\\
 $\bullet \quad z_0^R$ the average phenotype $z$ for the individuals in the same deme as the focal individual\\
 $\bullet \quad \bar{z}=\sum_k z_k / (n_I -1) $ the average phenotype $z$ for the individuals in demes different from the focal individual\\
 $\bullet \quad f (x)=ax+b$, $a>0$ a linear function describing the number of nematodes exiting the insect due to the phenotype (sacrifice) of bacteria.\\
 $\bullet \quad m=\sum{i=1}^V r q^{i-1}$ the total number of bacteria released in the insect at the moment of the last infection by nematodes.
 
 We assume the following life cycle, focusing on one particular individual in the $j$th insect:
 
 
 $\bullet$ (1) Starting when the last nematode infected the insect, previous result showed that the relatedness is fixed and the exponential growth and final population size has a negligible impact on relatedness
 
 
 $\bullet$ (2) $J_B$ bacteria are produced by the focal bacteria, they are in competition with $J_B m$ bacteria in the same insect (including those of the focal individual).
 
 
 $\bullet$ (3) After the nematode eat from the bacteria, there is only $J_B(1-z\bullet)$ offspring of the focal individual competing with $J_B m (1-z_j)$ offspring produced in the same insect (including those of the focal individual)
 
 
 $\bullet$ (4) $J_N f(z_j)$ nematodes are produced from the $j$th insect, they are in competition with $\sum_{i=1}^{n_I} J_N f(z_i)$ nematodes produced by all insect (including those produced by the insect of the focal individual)
 
 
 $\bullet$ (5) Only $V n_I$ nematodes will infect the next generation of insects. Since all nematodes are equivalent, the probability of being the $i$th $(1 \leq i \leq V)$ nematode infecting the insect 
is uniform, thus with probability $1/V$.If the nematode is the $i$th infecting the insect, the number of bacteria from this nematode at the moment of the last infection by nematodes is $r q^{i-1}$.
Thus, in expectation, there is $V n_I (\sum_{i=1}^V V^{-1}  r q^{i-1})=n_I m$ offspring of the focal one in the next cycle, conditioning on the carrying nematodes being from the one that succeded their infection in the next cycle. 


Putting together all parts of the cycle, we can compute $ w_j(z_\bullet , \mathbf{z} )$, the fitness of a focal individual in deme $j$:
 \begin{align}
 w_j(z_\bullet , \mathbf{z} ) &= \dfrac{J_B(1-z_\bullet)}{J_B m (1- z_j)}\dfrac{ J_N f(z_j)}{\sum_{i=1}^{n_I} J_N  f(z_i)} n_I m \\
 &= \dfrac{1-z_\bullet}{1- z_j}\dfrac{n_I f(z_j)}{\sum_{i=1}^{n_I} f(z_i)} \\
  &= \dfrac{1-z_\bullet}{1- z_j}\dfrac{n_I (a z_j +b) }{\sum_{i=1}^{n_I} (a z_i +b)}.
 \end{align}
 
 Since all demes are equivalent, for all demes $k$ different from the focal one, the $z_k$ variables contribute identically to the fitness measure. We write the fitness as a function of $z_\bullet$, $z_0^R$ and $\bar{z}$:
 
  \begin{align}
 w(z_\bullet ,z_0^R , \bar{z} ) &= \dfrac{1-z_\bullet}{1- z_0^R}\dfrac{n_I (a z_0^R +b) }{(a z_0^R +b)+ b(n_I -1) +a \bar{z} (n_I-1)} \\
 &= \dfrac{1-z_\bullet}{1- z_0^R}\dfrac{ a z_0^R +b }{a \left( \dfrac{z_0^R}{n_I} +\dfrac{n_I-1}{n_I} \bar{z} \right) +b}.
  \end{align}
  
  Under the model of infinite number of demes (insects), the fitness reduces to:
  
  \begin{equation}
  w(z_\bullet ,z_0^R , \bar{z} ) \simeq \lim_{n_I \rightarrow \infty} w_j(z_\bullet ,z_0^R , \bar{z} ) = \dfrac{1-z_\bullet}{1- z_0^R}\dfrac{a z_0^R +b }{a \bar{z} +b}.
  \end{equation}
  
  We then compute the partial derivative of the fitness with regard to $z_\bullet$ and $z_0^R$ and evaluate them at $z$:
  
  \begin{equation}
  \dfrac{\partial w(z_\bullet ,z_0^R , \bar{z} )}{\partial z_\bullet} = \dfrac{a z_0^R +b }{ (1 - z_0^R) (a \bar{z} +b) } \Rightarrow \left. \dfrac{\partial w(z_\bullet ,z_0^R , \bar{z} )}{\partial z_\bullet} \right\vert_{z_\bullet = z_0^R = \bar{z}=z} = \dfrac{1}{ 1 - z }.
  \end{equation}
  
  \begin{equation}
  \dfrac{\partial w(z_\bullet ,z_0^R , \bar{z} )}{\partial z_0^R} = \dfrac{(1- z_\bullet)(a +b)}{(1- z_0^R)^2(a \bar{z} +b)} \Rightarrow \left. \dfrac{\partial w(z_\bullet ,z_0^R , \bar{z} )}{\partial z_0^R} \right\vert_{z_\bullet = z_0^R = \bar{z}=z} = \dfrac{a +b}{(1- z)(a z +b)}.
  \end{equation}
  
  Solving $\left. \dfrac{\partial w}{\partial z_\bullet} \right\vert_{z^*} + \left. \dfrac{\partial w}{\partial z_0^R} \right\vert_{z^*} R =0 $ yields the evolutionary stable phenotype, see F. Rousset (2004) 
  
    \begin{equation}
  \dfrac{1}{ 1 - z^* } + \dfrac{a +b}{(1- z^*)(a z^* +b)}R =0
  \end{equation}
  \begin{equation}
  \iff
  \end{equation}
  \begin{equation}
  z^*=\dfrac{R(a+b)-b}{a}=R(1+c)-c \text{ where }c=\dfrac{b}{a}.
  \end{equation}
  
  
  In the special case $c=0$, the phenotype is the relatedness:
  \begin{equation}
  z^*=R.
  \end{equation}
  
  
  It is worth noticing that if $R<\dfrac{c}{c+1}$, then the evolutionary stable strategy is no cooperation $(z^*=0)$.
\end{document}